{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preprocessing on Churn Modelling"
      ],
      "metadata": {
        "id": "jmgNkE_JLVQ6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "importing necessary libraries which are required for preprocessing"
      ],
      "metadata": {
        "id": "v6To66J1LrGP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "F_brcrrFJsFN"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "we are going to use churn modelling dataset"
      ],
      "metadata": {
        "id": "sm-1L0ywL7I1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing the dataset\n",
        "dataset = pd.read_csv(\"Churn_Modelling.csv\")\n"
      ],
      "metadata": {
        "id": "3zQ6SauBJ6K-"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "extracts a subset of the dataset and assigns it to the variable X"
      ],
      "metadata": {
        "id": "5FkTUnOZMK3g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = dataset.iloc[:, 3:13].values\n",
        "y = dataset.iloc[:, 13].values\n",
        "print (X)\n",
        "print (y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ERKqkjpgKmNK",
        "outputId": "c394dda7-6f95-4df0-ec5e-ab4ad1e79257"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[619 'France' 'Female' ... 1 1 101348.88]\n",
            " [608 'Spain' 'Female' ... 0 1 112542.58]\n",
            " [502 'France' 'Female' ... 1 0 113931.57]\n",
            " ...\n",
            " [709 'France' 'Female' ... 0 1 42085.58]\n",
            " [772 'Germany' 'Male' ... 1 0 92888.52]\n",
            " [792 'France' 'Female' ... 1 0 38190.78]]\n",
            "[1 0 1 ... 1 1 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Encoding categorical data\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "ct = ColumnTransformer([(\"Geography\",OneHotEncoder(),[1])], remainder= 'passthrough')\n",
        "ct\n",
        "X = ct.fit_transform(X)\n",
        "labelencoder_X2 = LabelEncoder()\n",
        "X[:, 4] = labelencoder_X2.fit_transform(X[:, 4])\n",
        "X = X[: , 1:]\n",
        "print (X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "14iqsH5TJ-hF",
        "outputId": "595b5642-b43f-416e-ce3a-2110a3bc94e5"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.0 0.0 619 ... 1 1 101348.88]\n",
            " [0.0 1.0 608 ... 0 1 112542.58]\n",
            " [0.0 0.0 502 ... 1 0 113931.57]\n",
            " ...\n",
            " [0.0 0.0 709 ... 0 1 42085.58]\n",
            " [1.0 0.0 772 ... 1 0 92888.52]\n",
            " [0.0 0.0 792 ... 1 0 38190.78]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Splitting the dataset into the Training set and Test set\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n",
        "\n"
      ],
      "metadata": {
        "id": "mO3UlaeCKGLb"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Feature Scaling\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_test = sc.transform(X_test)\n",
        "print(X_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zf2GC9kZKdLT",
        "outputId": "00425208-f4c0-4fc2-e5ee-883baa43d426"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 1.75486502 -0.57369368 -0.55204276 ...  0.64259497  0.9687384\n",
            "   1.61085707]\n",
            " [-0.5698444  -0.57369368 -1.31490297 ...  0.64259497 -1.03227043\n",
            "   0.49587037]\n",
            " [-0.5698444   1.74309049  0.57162971 ...  0.64259497  0.9687384\n",
            "  -0.42478674]\n",
            " ...\n",
            " [-0.5698444   1.74309049 -0.74791227 ...  0.64259497 -1.03227043\n",
            "   0.71888467]\n",
            " [ 1.75486502 -0.57369368 -0.00566991 ...  0.64259497  0.9687384\n",
            "  -1.54507805]\n",
            " [ 1.75486502 -0.57369368 -0.79945688 ...  0.64259497 -1.03227043\n",
            "   1.61255917]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#now we can make model for further model evaluation"
      ],
      "metadata": {
        "id": "FdoWAe6vNo-o"
      }
    }
  ]
}